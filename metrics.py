import predict
import numpy as np
import table_data
import tensorflow as tf
import models
import etl
import pandas as pd
import pickle

# images path
IMAGES_GCS_PATH = 'gs://osic_fibrosis/images-norm/images-norm'

# image size
IMAGE_SIZE = (256, 256)


def laplace_log_likelihood(y_true, y_pred, theta):
    """Compute the Laplace Lop Likelihood score for the predictions y_pred.
    Args:
        y_true-ground truth values
        y_pred-predicted values
        theta-confidence measurements
    """

    theta_clipped = np.clip(theta, 70, None)
    delta = np.clip(np.abs(y_true - y_pred), 0, 1000)
    metric = - (np.sqrt(2) * delta) / theta_clipped - np.log(np.sqrt(2) * theta_clipped)
    return metric.sum() / len(y_true)


def get_lll_value_exp_function(id, exp_function, theta=200):
    """Return the laplace log likelihood score for a given patient and his exponent function."""
    hist = table_data.get_fvc_hist(table_data.get_train_table(), id)  # get ground truth

    # initiate predictions
    y_pred = []

    # get predictions
    for week in np.array(hist["Weeks"]):
        week = float(week)
        pred = exp_function(week)  # predict
        y_pred.append(pred)

    y_pred = np.array(y_pred)
    y_true = hist["FVC"]

    # compute_metric
    metric = laplace_log_likelihood(y_true, y_pred, theta)
    return metric


def exp_metric_check(exp_gen=None, n_patients=5, infinite=False):
    """Average n_patients random train patients Laplace Log Likelihood score for predictions generated by exp_gen.
    Args:
        exp_gen-generator yeilding id and exponent function for that id
        n_patients-number of patients to average
        infinite-whether to continue printing infinitely
    """

    scores = []

    if not exp_gen:
        exp_gen = predict.exponent_generator(IMAGES_GCS_PATH + '/train')

    # get scores
    for i, (id, func) in enumerate(exp_gen):
        score = get_lll_value_exp_function(id, func)
        scores.append(score)

        # exit rule
        if infinite:
            print(score) # for infinitely printing scores
        else:
            if i == n_patients - 1:
                break

    return sum(scores) / n_patients


def metric_check(qreg_model_path='models_weights/qreg_model/model_v3.ckpt',
                 processor_path='models_weights/qreg_model/preocessor.pickle',
                 pp_train_path='theta_data/pp_train.csv',
                 ):
    """
    Copmpute and print quantile regression model score and CNN only model score.

    :param qreg_model_path: path to quantile regression model weights
    :param processor_path: path to table preprocessor
    :param pp_train_path: path to preprocessed train table
    """

    dataset = pd.read_csv(pp_train_path)
    train_ids, val_ids = etl.get_train_val_split()

    # cast dtypes
    numeric_columns = dataset.select_dtypes(include=np.number).columns
    dataset[numeric_columns] = dataset[numeric_columns].astype('float32')

    train_dataset = dataset.loc[dataset["Patient"].isin(train_ids)]  # get train rows
    val_dataset = dataset.loc[dataset["Patient"].isin(val_ids)]  # get validation rows

    # split target
    train_y = train_dataset["GT_FVC"].values
    val_y = val_dataset["GT_FVC"].values
    train_x = train_dataset.drop(["GT_FVC", "Patient"], axis=1).values  # drop target and patient id
    val_x = val_dataset.drop(["GT_FVC", "Patient"], axis=1).values  # drop target and patient id

    # get model
    theta_model = models.get_qreg_model(train_x.shape[1])  # input vector n_dim is n columns
    theta_model.load_weights(qreg_model_path)

    model_preds = theta_model.predict(val_x)
    theta = model_preds[:, 2] - model_preds[:, 0]
    preds = model_preds[:, 1]

    # calculate qreg model score
    qreg_score = laplace_log_likelihood(val_y, preds, theta)
    print("Quantile regression model validation score is: {}".format(qreg_score))

    # calculate cnn model score
    processor = pickle.load(open(processor_path, 'rb'))
    processor.inverse_transform(val_dataset, 'FVC')
    cnn_score = laplace_log_likelihood(val_y, val_dataset["FVC"].values, 200)
    print("CNN only model validation score based on the preprocessed table is: {}".format(cnn_score))


# This section is taken from 'https://www.kaggle.com/chrisden/6-82-quantile-reg-lr-schedulers-checkpoints'
# I don't know who created the original kernel so I thank 'from coffee import *'
# from kaggle at https://www.kaggle.com/chrisden' from whom I copied this...

def score(y_true, y_pred):
    """Calculate the competition metric"""
    # create constants for the loss function
    C1, C2 = tf.constant(70, dtype='float32'), tf.constant(1000, dtype="float32")

    # cast dtypes
    tf.dtypes.cast(y_true, tf.float32)
    tf.dtypes.cast(y_pred, tf.float32)

    # compute sigma as the difference betwwen the marginal quantiles
    sigma = (y_pred[:, 2] - y_pred[:, 0])
    sigma_clip = tf.maximum(sigma, C1)

    # compute fvc as the median quantile
    fvc_pred = y_pred[:, 1]

    # compute delta as the error between ground truth and the computed median
    delta = tf.abs(y_true[:, 0] - fvc_pred)
    delta = tf.minimum(delta, C2)

    # compute metric
    sq2 = tf.sqrt(tf.dtypes.cast(2, dtype=tf.float32))
    metric = (delta / sigma_clip) * sq2 + tf.math.log(sigma_clip * sq2)

    return tf.keras.backend.mean(metric)


def qloss(y_true, y_pred):
    """Calculate Pinball loss"""
    # IMPORTANT: define quartiles, feel free to change here!
    qs = [0.2, 0.50, 0.8]
    q = tf.constant(np.array([qs]), dtype=tf.float32)
    e = y_true - y_pred
    v = tf.maximum(q * e, (q - 1) * e)
    return tf.keras.backend.mean(v)


def mloss(_lambda):
    """Combine Score and qloss.
    Args:
        _lambda: weighting constant for how much competition metric should be in the loss functio.
                 higher _lambda -> lower weight for the competition metric
    """

    def loss(y_true, y_pred):
        return _lambda * qloss(y_true, y_pred) + (1 - _lambda) * score(y_true, y_pred)

    return loss


if __name__ == "__main__":
    metric_check(
        qreg_model_path='models_weights/qreg_model/model_v3.ckpt',
        processor_path='models_weights/qreg_model/processor.pickle',
        pp_train_path='theta_data/pp_train.csv'
    )